# Model Optimization {#model-optim}

**Model Tuning**

Even though machine learning algorithms have default values set for their hyperparameters, these usually need to be modified by the user to achieve optimal performance.
Selecting suitable parameter values manually is not an easy task.
This is why an automatic tuning of hyperparameters is preferred.
Tuning hyperparameters implies automatic identification of values that lead to the best performance.
In order to tune a machine learning algorithm, you have to specify:

- the search space
- the optimization algorithm (aka tuning method)
- an evaluation method, i.e., a resampling strategy and a performance measure.

In summary, the sub-chapter on tuning illustrates hyperparameter selection, how to pick an optimizing algorithm and how to automate tuning using mlr3.

**Feature Selection** 

The second part of this chapter explains "feature selection".
The objective of feature selection is to fit the sparse dependent of a model on a subset of available data features in the most suitable manner.
Feature selection can enhance the interpretability of the model, speed up the learning process and improve the learner performance.
Different approaches exist to identify the relevant features.

The sub-chapter on feature selection introduces two distinct approaches to filtering namely on the one hand filtering and on the other hand feature subset selection.

**Nested Resampling**

In order to get a good estimate of generalization performance and avoid data leakage, both an outer (for tuning/feature selection) and an inner (for the base model) resampling process are advised.
mlr 3 supports nested resampling, which is used for complex operations such as tuning or feature selection through wrappers.

The third sub-section of this chapter will provide instructions on how to implement inner and outer resampling with mlr3.
