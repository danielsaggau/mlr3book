# mlr3 Basics {#basics}

This chapter will teach you the essential building blocks, R6 classes, and operations of `r mlr_pkg("mlr3")`.
This includes creating supervised machine learning tasks like [classification](#tasks), [regression](#tasks) and [training](#train-predict) models, getting [prediction](#train-predict) on new data, and evaluating and comparing different models through [cross-validation](#benchmarking) and [benchmarking](#benchmarking).

A typical machine learning workflow looks like this:

```{r 01-mlr3-basics-001, echo = FALSE}
knitr::include_graphics("images/ml_abstraction.png")
```

The data, which `r mlr_pkg("mlr3")` encapsulates in tasks, is split into non-overlapping train and test sets to be able to evaluate models objectively.
We are interested in models that generalize to new data rather than just memorizing the training data.
The training data is given to a machine learning algorithm, called a learner in `r mlr_pkg("mlr3")`.
The learner uses the training to build a model of how the features of the data relate to the target values.
This model is then used to produce predictions on the test data.
These predictions are compared to the ground truth values to assess the quality of the model.
`r mlr_pkg("mlr3")` offers a number of different measures to quantify this quality.
Usually this measure is a numeric score.
This process may be repeated several times.
Each time the process is repated, different train and test sets are resampled from the original data set.
Multiple resampling iterations allow us to get a better generalization performance estimate for a particular type of model.
This is done by quantifying its performance on different data.

The `r mlr_pkg("mlr3")` package provides R6 classes for the essential building blocks of this machine learning workflow:

* A [task](#tasks) encapsulates the data along with additional information, such as what the prediction target is.
* A [learners](#learners) encapsulates one of R's many machine learning algorithms and allows to train models and make predictions.
  Most learners have hyperparameters that affect their operation.
* A [measure](#measures) computes a numeric score based on predicted and ground-truth values and their difference.
* A [resampling](#resampling) specifies a series of train and test sets.

In many cases, this simple workflow is not sufficient to deal with real-world data, which may require normalization, imputation of missing values, or [feature selection](#fs).
We will cover more complex workflows that allow to do this and even more later in the book.
For now, we restrict ourselves to simple workflows like the one above for the sake of clarity.
